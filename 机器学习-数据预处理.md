## 导入库

```
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
```

## 加载数据

```
data = pd.read_excel('all_data.xlsx',sheet_name="all_data")
x_data = data.iloc[:,:-1]
y_data = data.iloc[:,-1]
```

## 查看数据特征

```
# 查看数据前几行
x_data.head()
# 统计数据的描述性统计信息
x_data.describe()
# 检查数据集的维度
x_data.shape
# 检查缺失值个数（列名：缺失值个数）
x_data.isnull().sum()
# 查看每列的数据类型
x_data.dtypes
```

## 查看某列独特值的个数

```
column_unique_values = {} # 保存每一列的独特值的个数（列名：该列独特值的个数）
all_columns = list(x_data.loc[:,:].columns.values)
for col in all_columns:
    column_unique_values[col] = len(x_data[col].unique())

column_unique_values
```

## 缺失值过多的列要被忽略

```
# 缺失值的个数超过0.5的属性列要被忽略（不用填充，不用找它和标签之间的关系）
ignore_features = list()
column_null_nums_series = x_data.isnull().sum()
column_null_nums_series
for col in column_null_nums_series.index:
    if (column_null_nums_series[col] / x_data.shape[0]) > 0.5:
        ignore_features.append(col)

# 获取其余的特征列
features = [i for i in x_data if i not in ignore_features]
# 删除缺失值过多的列
x_data = x_data[features]
```

## 填充缺失值

```
# 直接填充
x_data[column_name] = x_data[column_name].fillna('良好')

# 平均数、中位数、众数填充
# 1.那些列需要填充
need_fill_features = list()
column_series = x_data.isnull().sum()
for col in column_series.index:
    if column_series[col] > 0:
        need_fill_features.append(col)
need_fill_features
# 2.因为想要用样本所属类别的平均数/中位数/众数填充，所以临时合并特征和标签数据集
combined_data = pd.concat([x_data, y_data], axis=1)
# 3.填充
for fea in need_fill_features:
	combined_data[fea] = combined_data.groupby('labels')[fea].transform(lambda x: x.fillna(x.mean())) #平均数
    #combined_data[fea] = combined_data.groupby('labels')[fea].transform(lambda x: x.fillna(x.median())) #中位数
	#combined_data[fea] = combined_data.groupby('labels')[fea].transform(lambda x: x.fillna(x.mode().iloc[0])) #众数
```

## 将object类型转为category类型

```
obj_features = list(x_data.loc[:,x_data.dtypes == 'object'].columns.values)
for feature in obj_features:
    x_data[feature] = pd.Series(x_data[feature],dtype="category")
```

## category类型(分类特征)转为int类型

```
# 创建 LabelEncoder 对象
label_encoder = LabelEncoder()

# 循环应用 LabelEncoder 到每个分类特征
for feature in category_features:
    x_data[feature] = label_encoder.fit_transform(x_data[feature])
```

## 保存数据

```
# df是DataFrame对象
df.to_excel('data_CateToInt_FillNull.xlsx', index=False) 
```

## 查看样本类别分布

```
from collections import Counter
# 查看所生成的样本类别分布
print(Counter(y_data))
```

## 过采样

```
from imblearn.over_sampling import SMOTE
# 使用SMOTE-HMV进行过采样（要先处理缺失值，填充了所有的缺失值后才能过采样）
# 这里最奇怪！！！smote采样的数据类型不能是float，只能是int。所以要提前把数据的所有列从float64转为int64
smote_hmv = SMOTE(sampling_strategy='auto', k_neighbors=5)
x_resampled, y_resampled = smote_hmv.fit_resample(x_data, y_data)
```

```
# 提前把数据的所有float64类型的列转为int64
float_to_int_columns = list(x_data.loc[:,x_data.dtypes == 'float64'].columns.values)
for column_name in float_to_int_columns:
    x_data[column_name] = pd.Series(x_data[column_name],dtype="int64")
```

## 划分训练测试集

```
x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42) 
```

## 训练模型

```
# 用lightgbm模型做5分类
num_class = 5
params = {'objective': 'multiclass', 
          'n_estimators': 10, 
          'num_leaves': 2, 
          'num_class': num_class,
          'verbose': -1,
         'lambda_l1': 1.0,    # 调整L1正则化项的强度
        'lambda_l2': 1.0,    # 调整L2正则化项的强度
         }
train_dataset = lgb.Dataset(x_train, y_train)
test_dataset = lgb.Dataset(x_test, y_test)

# Using LightGBM's built-in objective
lgb_model = lgb.train(params=params,
                  train_set=train_dataset,
                  valid_sets=(train_dataset),
                  valid_names=('train'),
                  callbacks=[lgb.log_evaluation(1)])
```

## 预测和评估模型

```
# 预测
y_pred = model.predict(x_test)

# 评估模型
accuracy = accuracy_score(y_test, y_pred)
print("准确度:", accuracy)

# 计算精确度、召回率和F1分数  average可以是weighted,macro,micro
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')
print("精确度:", precision)
print("召回率:", recall)
print("F1分数:", f1)
```

